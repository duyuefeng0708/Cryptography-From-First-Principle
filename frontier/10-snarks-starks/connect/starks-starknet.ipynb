{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connect: STARKs in StarkNet\n",
    "\n",
    "**Module 10** | Real-World Connections\n",
    "\n",
    "*StarkNet processes transactions off-chain and posts STARK proofs to Ethereum for verification.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "**StarkNet** is a ZK rollup on Ethereum: it executes transactions off-chain, generates\n",
    "a STARK proof that all transactions were executed correctly, and posts only the proof\n",
    "to Ethereum. This achieves:\n",
    "\n",
    "| Property | Ethereum L1 | StarkNet L2 |\n",
    "|----------|-------------|-------------|\n",
    "| Execution | On-chain (every node) | Off-chain (prover only) |\n",
    "| Verification | Re-execute | **Verify STARK proof** |\n",
    "| Throughput | ~15 TPS | ~100-1000+ TPS |\n",
    "| Cost per tx | $1-50 | $0.01-0.10 |\n",
    "| Trust model | Consensus | **Math** (no trusted setup) |\n",
    "\n",
    "The STARK proof system uses the **FRI protocol** (Notebook 10e) as its polynomial\n",
    "commitment scheme, achieving **transparency** (no trusted setup) and **quantum resistance**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STARKs vs SNARKs in Practice\n",
    "\n",
    "| Feature | Groth16 (SNARK) | STARK |\n",
    "|---------|----------------|-------|\n",
    "| Trusted setup | **Yes** (circuit-specific ceremony) | **No** (transparent) |\n",
    "| Proof size | 192 bytes | ~50-200 KB |\n",
    "| Verification time | ~5 ms (3 pairings) | ~10-50 ms (hash checks) |\n",
    "| Prover time | $O(n \\log n)$ | $O(n \\log^2 n)$ |\n",
    "| Crypto assumption | Pairings, DLP | **Hash functions only** |\n",
    "| Quantum resistance | No | **Yes** |\n",
    "| Proof aggregation | Hard | Natural (recursive STARKs) |\n",
    "\n",
    "StarkNet chose STARKs because:\n",
    "1. No trusted setup needed (critical for decentralization)\n",
    "2. Quantum resistance (future-proofing)\n",
    "3. Fast prover for large computations\n",
    "4. Natural recursion for batching proofs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === The STARK pipeline: execution trace -> AIR -> FRI ===\n",
    "\n",
    "p = 257  # same field as Notebook 10e (Fermat prime, 2^8 + 1)\n",
    "F = GF(p)\n",
    "R.<X> = PolynomialRing(F)\n",
    "\n",
    "# Step 1: Execution Trace\n",
    "# In StarkNet, the execution trace records every step of a Cairo program.\n",
    "# We'll use a simple example: compute Fibonacci numbers mod p.\n",
    "\n",
    "# Fibonacci: a_{i+2} = a_{i+1} + a_i\n",
    "# Execution trace: [(a_0, a_1), (a_1, a_2), (a_2, a_3), ...]\n",
    "\n",
    "n_steps = 8  # must be power of 2 for FRI\n",
    "trace_col0 = [F(0)] * n_steps  # first column: a_i\n",
    "trace_col1 = [F(0)] * n_steps  # second column: a_{i+1}\n",
    "\n",
    "# Initial values\n",
    "trace_col0[0] = F(1)\n",
    "trace_col1[0] = F(1)\n",
    "\n",
    "# Fill the trace\n",
    "for i in range(1, n_steps):\n",
    "    trace_col0[i] = trace_col1[i-1]\n",
    "    trace_col1[i] = trace_col0[i-1] + trace_col1[i-1]\n",
    "\n",
    "print(\"=== Execution Trace (Fibonacci mod 257) ===\")\n",
    "print(f\"{'Step':>4} | {'a_i':>6} | {'a_{i+1}':>8}\")\n",
    "print(\"-\" * 25)\n",
    "for i in range(n_steps):\n",
    "    print(f\"{i:>4} | {ZZ(trace_col0[i]):>6} | {ZZ(trace_col1[i]):>8}\")\n",
    "\n",
    "print(f\"\\nThe prover claims: starting from (1,1), after {n_steps} Fibonacci steps,\")\n",
    "print(f\"the final value is a_{n_steps} = {ZZ(trace_col1[-1])}.\")\n",
    "print(f\"This is the execution trace that StarkNet would generate.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Encode trace as polynomials\n",
    "# Interpolate each column over a domain of size n_steps\n",
    "\n",
    "g = F.multiplicative_generator()\n",
    "omega = g^(256 // n_steps)  # primitive n_steps-th root of unity\n",
    "trace_domain = [omega^i for i in range(n_steps)]\n",
    "\n",
    "print(f\"Trace domain: omega = {omega}, omega^{n_steps} = {omega^n_steps}\")\n",
    "print(f\"Domain points: {[ZZ(d) for d in trace_domain]}\")\n",
    "print()\n",
    "\n",
    "# Interpolate: find polynomial f such that f(omega^i) = trace[i]\n",
    "points_col0 = list(zip(trace_domain, trace_col0))\n",
    "points_col1 = list(zip(trace_domain, trace_col1))\n",
    "\n",
    "f0 = R.lagrange_polynomial(points_col0)  # polynomial for column 0\n",
    "f1 = R.lagrange_polynomial(points_col1)  # polynomial for column 1\n",
    "\n",
    "print(f\"Trace polynomial f0(x) = {f0}\")\n",
    "print(f\"  degree: {f0.degree()} (< {n_steps})\")\n",
    "print(f\"Trace polynomial f1(x) = {f1}\")\n",
    "print(f\"  degree: {f1.degree()} (< {n_steps})\")\n",
    "print()\n",
    "\n",
    "# Verify interpolation\n",
    "print(\"Verification: f0(omega^i) should equal trace_col0[i]\")\n",
    "all_correct = all(f0(trace_domain[i]) == trace_col0[i] for i in range(n_steps))\n",
    "print(f\"  All correct? {all_correct}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: AIR Constraints (Algebraic Intermediate Representation)\n",
    "#\n",
    "# The Fibonacci recurrence imposes constraints on consecutive rows:\n",
    "#   f0(omega * x) = f1(x)           (column 0 shifts by one step)\n",
    "#   f1(omega * x) = f0(x) + f1(x)   (Fibonacci rule)\n",
    "#\n",
    "# These must hold for x in {omega^0, ..., omega^(n-2)} (all but the last row)\n",
    "\n",
    "# Constraint 1: f0(omega * x) - f1(x) = 0\n",
    "# Constraint 2: f1(omega * x) - f0(x) - f1(x) = 0\n",
    "\n",
    "# Construct the constraint polynomials\n",
    "# We evaluate f0(omega * x) by substituting omega*X into f0\n",
    "f0_shifted = f0(omega * X)  # f0 evaluated at the next trace row\n",
    "f1_shifted = f1(omega * X)  # f1 evaluated at the next trace row\n",
    "\n",
    "constraint1 = f0_shifted - f1\n",
    "constraint2 = f1_shifted - f0 - f1\n",
    "\n",
    "print(\"=== AIR Constraints ===\")\n",
    "print(f\"Constraint 1: f0(omega*x) - f1(x)\")\n",
    "print(f\"  degree: {constraint1.degree()}\")\n",
    "print(f\"Constraint 2: f1(omega*x) - f0(x) - f1(x)\")\n",
    "print(f\"  degree: {constraint2.degree()}\")\n",
    "print()\n",
    "\n",
    "# These constraints should vanish on {omega^0, ..., omega^(n-2)}\n",
    "# That is, on all points EXCEPT the last step omega^(n-1)\n",
    "print(\"Checking constraints on trace domain (except last row):\")\n",
    "for i in range(n_steps - 1):\n",
    "    x_val = trace_domain[i]\n",
    "    c1_val = constraint1(x_val)\n",
    "    c2_val = constraint2(x_val)\n",
    "    print(f\"  x = omega^{i} = {ZZ(x_val):>3}: C1 = {ZZ(c1_val)}, C2 = {ZZ(c2_val)}\")\n",
    "\n",
    "print(f\"\\nBoth constraints are 0 on all valid trace rows.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Vanishing polynomial and composition\n",
    "#\n",
    "# The constraints vanish on D' = {omega^0, ..., omega^(n-2)}\n",
    "# The vanishing polynomial for D' is:\n",
    "#   Z'(x) = (x^n - 1) / (x - omega^(n-1))\n",
    "\n",
    "# Vanishing polynomial for the full domain\n",
    "Z_full = X^n_steps - 1  # vanishes on all of {omega^0, ..., omega^(n-1)}\n",
    "\n",
    "# Remove the last point\n",
    "last_point = omega^(n_steps - 1)\n",
    "Z_constraint = Z_full // (X - last_point)\n",
    "\n",
    "print(\"=== Composition Polynomial ===\")\n",
    "print(f\"Vanishing polynomial Z'(x) = (x^{n_steps} - 1) / (x - {ZZ(last_point)})\")\n",
    "print(f\"  degree: {Z_constraint.degree()}\")\n",
    "print()\n",
    "\n",
    "# The STARK prover computes the composition polynomial:\n",
    "#   C(x) = constraint1(x) / Z'(x) + alpha * constraint2(x) / Z'(x)\n",
    "# where alpha is a random challenge from the verifier\n",
    "\n",
    "# If the constraints truly vanish on D', division is exact\n",
    "h1, r1 = constraint1.quo_rem(Z_constraint)\n",
    "h2, r2 = constraint2.quo_rem(Z_constraint)\n",
    "\n",
    "print(f\"Division check:\")\n",
    "print(f\"  C1 / Z': quotient degree {h1.degree()}, remainder = {r1}\")\n",
    "print(f\"  C2 / Z': quotient degree {h2.degree()}, remainder = {r2}\")\n",
    "print(f\"  Exact division? C1: {r1 == 0}, C2: {r2 == 0}\")\n",
    "print()\n",
    "\n",
    "# Random combination (Fiat-Shamir challenge)\n",
    "alpha_comb = F(7)\n",
    "composition = h1 + alpha_comb * h2\n",
    "print(f\"Composition polynomial: H(x) = h1(x) + {alpha_comb}*h2(x)\")\n",
    "print(f\"  degree: {composition.degree()}\")\n",
    "print(f\"\\nThis composition polynomial is what FRI proves is low-degree.\")\n",
    "print(f\"Low degree => constraints are satisfied => computation is correct.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The FRI Protocol in Action\n",
    "\n",
    "StarkNet's prover now runs FRI on the composition polynomial to prove it is low-degree.\n",
    "This is the connection to Notebook 10e:\n",
    "\n",
    "1. **Evaluate** the composition polynomial on a larger domain (blowup factor 4-8)\n",
    "2. **Commit** via Merkle tree\n",
    "3. **Fold** repeatedly, halving the degree each round\n",
    "4. **Verify** by spot-checking consistency of folding steps\n",
    "\n",
    "The proof consists of Merkle roots and authentication paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Run FRI on the composition polynomial ===\n",
    "\n",
    "import hashlib\n",
    "\n",
    "# Evaluation domain: 4x blowup\n",
    "eval_domain_size = 4 * n_steps  # 32 points\n",
    "omega_eval = g^(256 // eval_domain_size)\n",
    "eval_domain = [omega_eval^i for i in range(eval_domain_size)]\n",
    "\n",
    "# Evaluate composition polynomial on the evaluation domain\n",
    "comp_evals = [composition(d) for d in eval_domain]\n",
    "\n",
    "print(f\"=== FRI Setup ===\")\n",
    "print(f\"Composition polynomial degree: {composition.degree()}\")\n",
    "print(f\"Evaluation domain size: {eval_domain_size}\")\n",
    "print(f\"Rate: {composition.degree() + 1}/{eval_domain_size} = 1/{eval_domain_size // (composition.degree() + 1)}\")\n",
    "print()\n",
    "\n",
    "# Merkle commitment\n",
    "def merkle_root(values):\n",
    "    leaves = [hashlib.sha256(str(ZZ(v)).encode()).digest() for v in values]\n",
    "    while len(leaves) > 1:\n",
    "        if len(leaves) % 2 == 1:\n",
    "            leaves.append(leaves[-1])\n",
    "        leaves = [hashlib.sha256(leaves[i] + leaves[i+1]).digest()\n",
    "                  for i in range(0, len(leaves), 2)]\n",
    "    return leaves[0].hex()[:16]\n",
    "\n",
    "root = merkle_root(comp_evals)\n",
    "print(f\"Merkle commitment: {root}...\")\n",
    "print(f\"This is the first thing the prover sends.\")\n",
    "print()\n",
    "\n",
    "# FRI folding\n",
    "def even_odd_split(poly):\n",
    "    coeffs = poly.padded_list(poly.degree() + 1) if poly.degree() >= 0 else [F(0)]\n",
    "    if len(coeffs) % 2 == 1:\n",
    "        coeffs.append(F(0))\n",
    "    return R(coeffs[0::2]), R(coeffs[1::2])\n",
    "\n",
    "def fri_fold(poly, alpha, domain):\n",
    "    f_even, f_odd = even_odd_split(poly)\n",
    "    folded = f_even + alpha * f_odd\n",
    "    new_domain = sorted(set(d^2 for d in domain), key=lambda x: ZZ(x))\n",
    "    return folded, new_domain\n",
    "\n",
    "# Fold until constant\n",
    "current = composition\n",
    "current_domain = eval_domain\n",
    "round_num = 0\n",
    "challenges = [F(13), F(29), F(41)]  # Fiat-Shamir challenges\n",
    "\n",
    "print(f\"=== FRI Folding ===\")\n",
    "print(f\"Round {round_num}: degree {current.degree()}, domain size {len(current_domain)}\")\n",
    "\n",
    "for alpha_fri in challenges:\n",
    "    if current.degree() <= 0:\n",
    "        break\n",
    "    current, current_domain = fri_fold(current, alpha_fri, current_domain)\n",
    "    round_num += 1\n",
    "    print(f\"Round {round_num}: degree {current.degree()}, domain size {len(current_domain)}, alpha = {alpha_fri}\")\n",
    "\n",
    "print(f\"\\nFinal constant: {ZZ(current.constant_coefficient())}\")\n",
    "print(f\"Prover sends: {round_num} Merkle roots + final constant\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recursive STARKs and SHARP\n",
    "\n",
    "StarkNet uses **SHARP** (Shared Prover) to batch multiple transactions into one proof:\n",
    "\n",
    "1. Collect 100-1000 transactions\n",
    "2. Execute them all, producing a large execution trace\n",
    "3. Generate ONE STARK proof for the entire batch\n",
    "4. Post the proof to Ethereum L1\n",
    "\n",
    "For even more efficiency, StarkNet uses **recursive STARKs**: prove that you verified\n",
    "a previous STARK proof, compressing multiple proofs into one.\n",
    "\n",
    "```\n",
    "Batch 1 (100 txs) --> STARK proof P1\n",
    "Batch 2 (100 txs) --> STARK proof P2\n",
    "Batch 3 (100 txs) --> STARK proof P3\n",
    "                        |\n",
    "                        v\n",
    "Recursive proof: \"P1, P2, P3 are all valid\" --> STARK proof P_combined\n",
    "                        |\n",
    "                        v\n",
    "                Post P_combined to Ethereum (one proof for 300 txs)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Cost analysis: STARK proof batching ===\n",
    "\n",
    "print(\"=== StarkNet Proof Economics ===\")\n",
    "print()\n",
    "\n",
    "# L1 Ethereum gas costs\n",
    "gas_per_calldata_byte = 16  # EIP-4844 makes this cheaper with blobs\n",
    "l1_gas_price_gwei = 30  # typical gas price\n",
    "gwei_per_eth = 10^9\n",
    "\n",
    "# STARK proof sizes\n",
    "stark_proof_kb = 100  # ~100 KB typical\n",
    "stark_proof_bytes = stark_proof_kb * 1024\n",
    "\n",
    "# Cost per proof on L1\n",
    "calldata_gas = stark_proof_bytes * gas_per_calldata_byte\n",
    "verification_gas = 500000  # STARK verification on-chain\n",
    "total_gas = calldata_gas + verification_gas\n",
    "\n",
    "# Cost in ETH\n",
    "cost_gwei = total_gas * l1_gas_price_gwei\n",
    "cost_eth = cost_gwei / gwei_per_eth\n",
    "\n",
    "print(f\"{'Metric':<35} {'Value':>15}\")\n",
    "print(\"-\" * 52)\n",
    "print(f\"{'STARK proof size':<35} {'~100 KB':>15}\")\n",
    "print(f\"{'Calldata gas':<35} {f'{calldata_gas:,} gas':>15}\")\n",
    "print(f\"{'Verification gas':<35} {f'{verification_gas:,} gas':>15}\")\n",
    "print(f\"{'Total gas per proof':<35} {f'{total_gas:,} gas':>15}\")\n",
    "print()\n",
    "\n",
    "# Amortize over transactions\n",
    "for n_txs in [10, 100, 1000, 10000]:\n",
    "    cost_per_tx = total_gas / n_txs\n",
    "    print(f\"  {n_txs:>5} txs/batch: {cost_per_tx:>10,.0f} gas/tx\")\n",
    "\n",
    "print(f\"\\nWith 10,000 txs per batch, each tx costs ~{total_gas/10000:.0f} gas\")\n",
    "print(f\"vs ~21,000 gas for a basic L1 Ethereum transfer.\")\n",
    "print(f\"That is a ~{21000 / (total_gas / 10000):.0f}x cost reduction!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cairo: StarkNet's STARK-Native Language\n",
    "\n",
    "StarkNet programs are written in **Cairo**, a language designed to produce execution\n",
    "traces that are efficient for STARK proving:\n",
    "\n",
    "- Every Cairo program compiles to an **algebraic execution trace**\n",
    "- The trace satisfies **AIR constraints** (Algebraic Intermediate Representation)\n",
    "- The constraints are checked by FRI polynomial proximity testing\n",
    "\n",
    "Cairo's computational model is based on a **register machine** where all operations\n",
    "are field arithmetic over a large prime field ($p \\approx 2^{251}$ in production)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Concept Map: Module 10 -> StarkNet ===\n",
    "\n",
    "print(\"=== Concept Map ===\")\n",
    "print()\n",
    "concept_map = [\n",
    "    (\"Execution trace\", \"AIR constraints\",\n",
    "     \"Cairo program produces trace; AIR encodes correctness rules\"),\n",
    "    (\"Polynomial interpolation\", \"Trace polynomials\",\n",
    "     \"Trace columns become polynomials over evaluation domain\"),\n",
    "    (\"Vanishing polynomial\", \"Constraint satisfaction\",\n",
    "     \"Constraints vanish on trace domain iff computation is correct\"),\n",
    "    (\"FRI protocol\", \"Polynomial commitment\",\n",
    "     \"Proves composition polynomial is low-degree (hash-based, transparent)\"),\n",
    "    (\"Merkle trees\", \"Commitment scheme\",\n",
    "     \"Prover commits to evaluations; verifier spot-checks\"),\n",
    "    (\"Fiat-Shamir\", \"Non-interactive proofs\",\n",
    "     \"Hash-based challenges make the protocol non-interactive\"),\n",
    "    (\"Recursive STARKs\", \"Proof batching\",\n",
    "     \"SHARP batches thousands of txs into one Ethereum proof\"),\n",
    "]\n",
    "\n",
    "for concept, application, explanation in concept_map:\n",
    "    print(f\"  {concept} --> {application}\")\n",
    "    print(f\"    {explanation}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "StarkNet is Module 10 at Ethereum scale:\n",
    "\n",
    "- **Cairo programs** produce algebraic execution traces.\n",
    "- **AIR constraints** enforce computational correctness as polynomial identities.\n",
    "- **FRI** proves the composition polynomial is low-degree, confirming all constraints hold.\n",
    "- **No trusted setup**: all verifier randomness comes from Fiat-Shamir hashing.\n",
    "- **SHARP** batches thousands of transactions into a single proof posted to Ethereum.\n",
    "- **Recursive STARKs** compress multiple proofs into one, further reducing L1 costs.\n",
    "\n",
    "The trade-off vs Groth16: proofs are larger (~100 KB vs 192 bytes), but transparency\n",
    "and quantum resistance make STARKs attractive for large-scale rollups.\n",
    "\n",
    "---\n",
    "\n",
    "*Back to [Module 10: SNARKs and STARKs](../README.md)*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SageMath 10.0",
   "language": "sage",
   "name": "sagemath"
  },
  "language_info": {
   "name": "sage"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}